{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "pycharm-ca37dc",
   "language": "python",
   "display_name": "PyCharm (HW2)"
  },
  "colab": {
   "name": "NoStrategy.ipynb",
   "provenance": [],
   "include_colab_link": true
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10d705fd5059420599b86d826a75fe60": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_49333ad439af4acd8eb9d83ae1248ec2",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_bc71fc3be4974cecb37ba22785724871",
       "IPY_MODEL_c404425a8622414ca1104200143740cf"
      ]
     }
    },
    "49333ad439af4acd8eb9d83ae1248ec2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "bc71fc3be4974cecb37ba22785724871": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_c32748ab73ed4b9f93bb62a3ad9dc5e7",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "info",
      "max": 1,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_45238964f6574779a1e56cb275b18713"
     }
    },
    "c404425a8622414ca1104200143740cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_3fca3aa7f04f45d491b16c424a0ae4a5",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 170500096/? [00:29&lt;00:00, 17232253.24it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_0770cd7877e844aeb62c7de76a48fccb"
     }
    },
    "c32748ab73ed4b9f93bb62a3ad9dc5e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "45238964f6574779a1e56cb275b18713": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "3fca3aa7f04f45d491b16c424a0ae4a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "0770cd7877e844aeb62c7de76a48fccb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/pI88Id/MLProject-Incremental.Learning/blob/master/NoStrategy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "bQQVMi4fThDL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.backends import cudnn\n",
    "import os\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from Cifar100 import Cifar100\n",
    "from Cifar100 import utils\n",
    "\n",
    "# if not os.path.isdir('a'):\n",
    "#     !git clone https://github.com/pI88Id/MLProject-Incremental.Learning.git\n",
    "#     os.rename(\"MLProject-Incremental.Learning\",\"a\")\n",
    "# from a.Cifar100.Cifar100 import  import Cifar100"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "dXKxvIpQThDZ",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Set Arguments**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "wV7UkWqiThDb",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
    "\n",
    "NUM_CLASSES = 100\n",
    "CLASSES_EACH_TRAIN = 10\n",
    "\n",
    "BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
    "                    # the batch size, learning rate should change by the same factor to have comparable results\n",
    "\n",
    "LR = 1e-3            # The initial Learning Rate\n",
    "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
    "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
    "\n",
    "NUM_EPOCHS = 5  #30    # Total number of training epochs (iterations over dataset)\n",
    "STEP_SIZE = 2  #30    # How many epochs before decreasing learning rate (if using a step-down policy)\n",
    "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
    "\n",
    "LOG_FREQUENCY = 10"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Define Data Preprocessing**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Define transforms for training phase\n",
    "train_transform = transforms.Compose([transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
    "                                    ])\n",
    "\n",
    "# Define transforms for the evaluation phase\n",
    "eval_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "X1kTkTyOThDn",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Prepare Network**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "A9MAByeCThDo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "net = resnet18()\n",
    "best_net = resnet18()\n",
    "\n",
    "net.fc = nn.Linear(net.fc.in_features, NUM_CLASSES)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "y92MNLEjThDx",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Prepare Training**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "YfijaWiiThDy",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
    "\n",
    "parameters_to_optimize = net.parameters()\n",
    "\n",
    "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "# optimizer = optim.Adam(parameters_to_optimize, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Define scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "TdKpn8TwThD5",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "F_aPAjhCThD6",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "net = net.to(DEVICE)\n",
    "cudnn.benchmark = True # Calling this optimizes runtime\n",
    "\n",
    "current_step = 0\n",
    "best_accuracy = 0\n",
    "loss = 0\n",
    "index = 0\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "loss_train = []\n",
    "loss_test = []"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Cifar100 - DATASET CREATED\n",
      "Train Dataset: 50000\n",
      "Test Dataset: 10000\n",
      "index 0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1/5, LR = [0.001]\n",
      "Step 0, Loss 4.936495304107666\n",
      "Step 10, Loss 3.5694146156311035\n",
      "Starting epoch 2/5, LR = [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PiC\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#New variable from our class Cifar100\n",
    "cifar100 = Cifar100.Cifar100(BATCH_SIZE, NUM_EPOCHS, DEVICE, LR, STEP_SIZE, GAMMA)\n",
    "\n",
    "for index in range(0, int(NUM_CLASSES/CLASSES_EACH_TRAIN)):\n",
    "\n",
    "  print('index', index)\n",
    "  #Load data from Cifar100\n",
    "  train_dataset = utils.Cifar100(classes=range(10), train=True, transform=train_transform)\n",
    "  test_dataset = utils.Cifar100(classes=range(10), train=False, transform=train_transform)\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, drop_last=True)\n",
    "  test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8) #Batch_size decrease for GPU ram problems\n",
    "\n",
    "  # train_dataloader = cifar100.load('train', index=index)\n",
    "  # test_dataloader = cifar100.load('test', index=index)\n",
    "\n",
    "\n",
    "  # Start iterating over the epochs\n",
    "  for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
    "    running_correct=0\n",
    "\n",
    "    # Iterate over the dataset\n",
    "    for _, images, labels in train_dataloader:\n",
    "\n",
    "      # Bring data over the device of choice\n",
    "      images = images.to(DEVICE)\n",
    "      labels = labels.to(DEVICE)\n",
    "\n",
    "      net.train().to(DEVICE)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(images)\n",
    "\n",
    "      #Calc the correct for the graph\n",
    "      _, preds = torch.max(outputs.data, 1)\n",
    "      running_correct += torch.sum(preds == labels.data).data.item()\n",
    "\n",
    "      # Compute loss based on output and ground truth\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      # Log loss\n",
    "      if current_step % LOG_FREQUENCY == 0:\n",
    "        print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
    "\n",
    "      # Compute gradients for each layer and update weights\n",
    "      loss.backward()  # backward pass: computes gradients\n",
    "      optimizer.step() # update weights based on accumulated gradients\n",
    "\n",
    "      current_step += 1\n",
    "\n",
    "    loss_train.append(loss.item())\n",
    "    accuracy_train.append(running_correct / float(len(train_dataloader)))\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "  # accuracy, loss = cifar100.test(net, test_dataloader, criterion)\n",
    "\n",
    "  # loss_test.append(loss.item())\n",
    "  # accuracy_test.append(accuracy)\n",
    "  # print('Test Accuracy: {}'.format(accuracy))\n",
    "  #\n",
    "  #\n",
    "  # if accuracy > best_accuracy:\n",
    "  #   best_net = copy.deepcopy(net)\n",
    "  #   best_accuracy = accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "zNldkdTXThED",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902,
     "referenced_widgets": [
      "10d705fd5059420599b86d826a75fe60",
      "49333ad439af4acd8eb9d83ae1248ec2",
      "bc71fc3be4974cecb37ba22785724871",
      "c404425a8622414ca1104200143740cf",
      "c32748ab73ed4b9f93bb62a3ad9dc5e7",
      "45238964f6574779a1e56cb275b18713",
      "3fca3aa7f04f45d491b16c424a0ae4a5",
      "0770cd7877e844aeb62c7de76a48fccb"
     ]
    },
    "outputId": "5ed91fa0-5932-4c5e-b10e-dcaa2de8a3e9"
   },
   "source": [
    "**Plots**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "3MIXOOuEThEL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# cifar100.plot(accuracy_train, accuracy_test, loss_train, loss_test)\n",
    "# print('Best accuracy', best_accuracy)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}