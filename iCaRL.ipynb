{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.backends import cudnn\n",
    "import os\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "if not os.path.isdir('a'):\n",
    "    !git clone https://github.com/pI88Id/MLProject-Incremental.Learning.git\n",
    "    os.rename(\"MLProject-Incremental.Learning\",\"a\")\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from a.Cifar100.Cifar100 import Cifar100\n",
    "from Cifar100 import utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Set Arguments**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
    "\n",
    "NUM_CLASSES = 100\n",
    "CLASSES_EACH_TRAIN = 10\n",
    "\n",
    "BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
    "                    # the batch size, learning rate should change by the same factor to have comparable results\n",
    "\n",
    "LR = 1e-3            # The initial Learning Rate\n",
    "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
    "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
    "\n",
    "NUM_EPOCHS = 5  #30    # Total number of training epochs (iterations over dataset)\n",
    "STEP_SIZE = 2  #30    # How many epochs before decreasing learning rate (if using a step-down policy)\n",
    "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
    "\n",
    "LOG_FREQUENCY = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Define Data Preprocessing**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define transforms for training phase\n",
    "train_transform = transforms.Compose([transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
    "                                    ])\n",
    "\n",
    "# Define transforms for the evaluation phase\n",
    "eval_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Prepare Network**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = resnet18()\n",
    "best_net = resnet18()\n",
    "\n",
    "net.fc = nn.Linear(net.fc.in_features, NUM_CLASSES)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Prepare Training**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
    "\n",
    "parameters_to_optimize = net.parameters()\n",
    "\n",
    "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "# optimizer = optim.Adam(parameters_to_optimize, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Define scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Train and Test**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = net.to(DEVICE)\n",
    "cudnn.benchmark = True # Calling this optimizes runtime\n",
    "\n",
    "current_step = 0\n",
    "best_accuracy = 0\n",
    "loss = 0\n",
    "index = 0\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "loss_train = []\n",
    "loss_test = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#New variable from our class Cifar100\n",
    "# cifar100 = Cifar100(BATCH_SIZE, NUM_EPOCHS, DEVICE, LR, STEP_SIZE, GAMMA)\n",
    "\n",
    "for index in range(0, int(NUM_CLASSES/CLASSES_EACH_TRAIN)):\n",
    "\n",
    "  print('index', index)\n",
    "  #Load data from Cifar100\n",
    "  train_dataset = utils.Cifar100(classes=range(10), train=True, transform=train_transform)\n",
    "  test_dataset = utils.Cifar100(classes=range(10), train=False, transform=train_transform)\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, drop_last=True)\n",
    "  test_dataloader = DataLoader(test_dataset, batch_size=int(BATCH_SIZE), shuffle=False, num_workers=8) #Batch_size decrease for GPU ram problems\n",
    "\n",
    "  # train_dataloader = cifar100.load('train', index=index)\n",
    "  # test_dataloader = cifar100.load('test', index=index)\n",
    "\n",
    "\n",
    "  # Start iterating over the epochs\n",
    "  for epoch in range(NUM_EPOCHS):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-ca37dc",
   "language": "python",
   "display_name": "PyCharm (HW2)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}