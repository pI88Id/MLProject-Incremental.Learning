{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "pycharm-ca37dc",
   "language": "python",
   "display_name": "PyCharm (HW2)"
  },
  "colab": {
   "name": "NoStrategy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "l7dwNWfvByP5",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pI88Id/MLProject-Incremental.Learning/blob/master/NoStrategy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "bQQVMi4fThDL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.backends import cudnn\n",
    "import os\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#if not os.path.isdir('a'):\n",
    "  #!git clone https://github.com/pI88Id/MLProject-Incremental.Learning.git\n",
    "  #os.rename(\"MLProject-Incremental.Learning\",\"a\")\n",
    "\n",
    "#from a.Cifar100  import Cifar100\n",
    "#from a.Cifar100 import utils\n",
    "from Cifar100 import Cifar100\n",
    "from Cifar100 import utils"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "dXKxvIpQThDZ",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Set Arguments**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "wV7UkWqiThDb",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
    "\n",
    "NUM_CLASSES = 100\n",
    "CLASSES_EACH_TRAIN = 10\n",
    "\n",
    "BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
    "                    # the batch size, learning rate should change by the same factor to have comparable results\n",
    "\n",
    "LR = 1e-3            # The initial Learning Rate\n",
    "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
    "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
    "\n",
    "NUM_EPOCHS = 5  #30    # Total number of training epochs (iterations over dataset)\n",
    "STEP_SIZE = 2  #30    # How many epochs before decreasing learning rate (if using a step-down policy)\n",
    "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
    "\n",
    "LOG_FREQUENCY = 10"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "e7ZrhfMaByQU",
    "colab_type": "text"
   },
   "source": [
    "**Define Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "0ur_kT_rByQV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Define transforms for training phase\n",
    "train_transform = transforms.Compose([transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
    "                                    ])\n",
    "\n",
    "# Define transforms for the evaluation phase\n",
    "eval_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                    ])"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "X1kTkTyOThDn",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Prepare Network**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "A9MAByeCThDo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "net = resnet18()\n",
    "best_net = resnet18()\n",
    "\n",
    "net.fc = nn.Linear(net.fc.in_features, NUM_CLASSES)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "y92MNLEjThDx",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Prepare Training**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "YfijaWiiThDy",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
    "\n",
    "parameters_to_optimize = net.parameters()\n",
    "\n",
    "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "# optimizer = optim.Adam(parameters_to_optimize, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Define scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "TdKpn8TwThD5",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "F_aPAjhCThD6",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "net = net.to(DEVICE)\n",
    "cudnn.benchmark = True # Calling this optimizes runtime\n",
    "\n",
    "current_step = 0\n",
    "best_accuracy = 0\n",
    "loss = 0\n",
    "index = 0\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "loss_train = []\n",
    "loss_test = []"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "M57J7H7eByQ0",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "fedc83ec-1df3-464b-9297-1f957b9665e5"
   },
   "source": [
    "#New variable from our class Cifar100\n",
    "cifar100 = Cifar100.Cifar100(BATCH_SIZE, NUM_EPOCHS, DEVICE, LR, STEP_SIZE, GAMMA)\n",
    "\n",
    "tot_step = NUM_CLASSES//CLASSES_EACH_TRAIN\n",
    "\n",
    "for index in range(0, NUM_CLASSES//CLASSES_EACH_TRAIN):\n",
    "  start = index*CLASSES_EACH_TRAIN\n",
    "  stop = (index+1)*CLASSES_EACH_TRAIN\n",
    "\n",
    "  #Load data from Cifar100\n",
    "  train_dataset = utils.Cifar100(classes=range(start, stop), train=True, transform=train_transform)\n",
    "  test_dataset = utils.Cifar100(classes=range(start, stop), train=False, transform=train_transform)\n",
    "  test_dataset_all= utils.Cifar100(classes=range(stop), train=False, transform=train_transform)\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, drop_last=True)\n",
    "  test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8) #Batch_size decrease for GPU ram problems\n",
    "\n",
    "  # train_dataloader = cifar100.load('train', index=index)\n",
    "  # test_dataloader = cifar100.load('test', index=index)\n",
    "\n",
    "\n",
    "  # Start iterating over the epochs\n",
    "  for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
    "    running_correct=0\n",
    "\n",
    "    # Iterate over the dataset\n",
    "    for _, images, labels in train_dataloader:\n",
    "\n",
    "      # Bring data over the device of choice\n",
    "      images = images.to(DEVICE)\n",
    "      labels = labels.to(DEVICE)\n",
    "\n",
    "      net.train().to(DEVICE)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(images)\n",
    "\n",
    "      #Calc the correct for the graph\n",
    "      _, preds = torch.max(outputs.data, 1)\n",
    "      running_correct += torch.sum(preds == labels.data).data.item()\n",
    "\n",
    "      # Compute loss based on output and ground truth\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      # Log loss\n",
    "      if current_step % LOG_FREQUENCY == 0:\n",
    "        print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
    "\n",
    "      # Compute gradients for each layer and update weights\n",
    "      loss.backward()  # backward pass: computes gradients\n",
    "      optimizer.step() # update weights based on accumulated gradients\n",
    "\n",
    "      current_step += 1\n",
    "\n",
    "    loss_train.append(loss.item())\n",
    "    \n",
    "    accuracy_train.append(running_correct / float(len(train_dataloader)))\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "  accuracy, loss = cifar100.test(net, test_dataloader, criterion)\n",
    "\n",
    "  loss_test.append(loss.item())\n",
    "  accuracy_test.append(accuracy)\n",
    "  print('Test Accuracy: {}'.format(accuracy))\n",
    "\n",
    "\n",
    "  if accuracy > best_accuracy:\n",
    "    best_net = copy.deepcopy(net)\n",
    "    best_accuracy = accuracy\n"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Cifar100 - DATASET CREATED\n",
      "Train Dataset: 50000\n",
      "Test Dataset: 10000\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1/5, LR = [0.001]\n",
      "Step 0, Loss 5.114832878112793\n",
      "Step 10, Loss 3.7776618003845215\n",
      "Starting epoch 2/5, LR = [0.001]\n",
      "Step 20, Loss 2.3600919246673584\n",
      "Step 30, Loss 2.0106046199798584\n",
      "Starting epoch 3/5, LR = [1e-05]\n",
      "Step 40, Loss 1.7578074932098389\n",
      "Step 50, Loss 1.7493127584457397\n",
      "Starting epoch 4/5, LR = [0.0001]\n",
      "Step 60, Loss 1.8127235174179077\n",
      "Step 70, Loss 1.695968747138977\n",
      "Starting epoch 5/5, LR = [1.0000000000000002e-06]\n",
      "Step 80, Loss 1.6017626523971558\n",
      "Step 90, Loss 1.7916892766952515\n",
      "Test Accuracy: 106.5\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1/5, LR = [1e-05]\n",
      "Step 100, Loss 8.059751510620117\n",
      "Step 110, Loss 8.081120491027832\n",
      "Starting epoch 2/5, LR = [1.0000000000000002e-07]\n",
      "Step 120, Loss 8.095730781555176\n",
      "Step 130, Loss 8.047794342041016\n",
      "Starting epoch 3/5, LR = [1.0000000000000002e-06]\n",
      "Step 140, Loss 8.038013458251953\n",
      "Step 150, Loss 8.029075622558594\n",
      "Starting epoch 4/5, LR = [1.0000000000000004e-08]\n",
      "Step 160, Loss 8.012863159179688\n",
      "Step 170, Loss 7.917147636413574\n",
      "Starting epoch 5/5, LR = [1.0000000000000002e-07]\n",
      "Step 180, Loss 7.9476704597473145\n",
      "Test Accuracy: 0.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1/5, LR = [1.0000000000000005e-09]\n",
      "Step 190, Loss 8.211703300476074\n",
      "Step 200, Loss 8.134398460388184\n",
      "Starting epoch 2/5, LR = [1.0000000000000004e-08]\n",
      "Step 210, Loss 8.161420822143555\n",
      "Step 220, Loss 8.225359916687012\n",
      "Starting epoch 3/5, LR = [1.0000000000000006e-10]\n",
      "Step 230, Loss 8.238114356994629\n",
      "Step 240, Loss 8.177971839904785\n",
      "Starting epoch 4/5, LR = [1.0000000000000005e-09]\n",
      "Step 250, Loss 8.160852432250977\n",
      "Step 260, Loss 8.166666030883789\n",
      "Starting epoch 5/5, LR = [1.0000000000000006e-11]\n",
      "Step 270, Loss 8.259245872497559\n",
      "Step 280, Loss 8.11229419708252\n",
      "Test Accuracy: 0.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1/5, LR = [1.0000000000000006e-10]\n",
      "Step 290, Loss 7.9538445472717285\n",
      "Step 300, Loss 7.9622416496276855\n",
      "Starting epoch 2/5, LR = [1.0000000000000006e-12]\n",
      "Step 310, Loss 7.995842933654785\n",
      "Step 320, Loss 7.953732013702393\n",
      "Starting epoch 3/5, LR = [1.0000000000000006e-11]\n",
      "Step 330, Loss 7.919417858123779\n",
      "Step 340, Loss 7.933074474334717\n",
      "Starting epoch 4/5, LR = [1.0000000000000007e-13]\n",
      "Step 350, Loss 8.001388549804688\n",
      "Step 360, Loss 7.954430103302002\n",
      "Starting epoch 5/5, LR = [1.0000000000000006e-12]\n",
      "Step 370, Loss 7.9163498878479\n",
      "Test Accuracy: 0.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1/5, LR = [1.0000000000000008e-14]\n",
      "Step 380, Loss 8.008767127990723\n",
      "Step 390, Loss 8.019827842712402\n",
      "Starting epoch 2/5, LR = [1.0000000000000007e-13]\n",
      "Step 400, Loss 7.998103141784668\n",
      "Step 410, Loss 7.957417011260986\n",
      "Starting epoch 3/5, LR = [1.0000000000000009e-15]\n",
      "Step 420, Loss 7.982581615447998\n",
      "Step 430, Loss 7.966521263122559\n",
      "Starting epoch 4/5, LR = [1.0000000000000008e-14]\n",
      "Step 440, Loss 7.97390604019165\n",
      "Step 450, Loss 8.007421493530273\n",
      "Starting epoch 5/5, LR = [1.000000000000001e-16]\n",
      "Step 460, Loss 8.000958442687988\n",
      "Step 470, Loss 8.043970108032227\n",
      "Test Accuracy: 0.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1/5, LR = [1.0000000000000009e-15]\n",
      "Step 480, Loss 8.108159065246582\n",
      "Step 490, Loss 8.148365020751953\n",
      "Starting epoch 2/5, LR = [1.000000000000001e-17]\n",
      "Step 500, Loss 8.151511192321777\n",
      "Step 510, Loss 8.13151741027832\n",
      "Starting epoch 3/5, LR = [1.000000000000001e-16]\n",
      "Step 520, Loss 8.137099266052246\n",
      "Step 530, Loss 8.229266166687012\n",
      "Starting epoch 4/5, LR = [1.000000000000001e-18]\n",
      "Step 540, Loss 8.19604778289795\n",
      "Step 550, Loss 8.088019371032715\n",
      "Starting epoch 5/5, LR = [1.000000000000001e-17]\n",
      "Step 560, Loss 8.19250202178955\n",
      "Test Accuracy: 0.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1/5, LR = [1.000000000000001e-19]\n",
      "Step 570, Loss 7.910899639129639\n",
      "Step 580, Loss 7.934061050415039\n",
      "Starting epoch 2/5, LR = [1.000000000000001e-18]\n",
      "Step 590, Loss 7.916289329528809\n",
      "Step 600, Loss 7.913590431213379\n",
      "Starting epoch 3/5, LR = [1.0000000000000011e-20]\n",
      "Step 610, Loss 7.893091678619385\n",
      "Step 620, Loss 7.889493465423584\n",
      "Starting epoch 4/5, LR = [1.000000000000001e-19]\n",
      "Step 630, Loss 7.921795845031738\n",
      "Step 640, Loss 7.854617595672607\n",
      "Starting epoch 5/5, LR = [1.0000000000000012e-21]\n",
      "Step 650, Loss 7.898449897766113\n",
      "Step 660, Loss 7.913041591644287\n",
      "Test Accuracy: 0.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1/5, LR = [1.0000000000000011e-20]\n",
      "Step 670, Loss 7.977016448974609\n",
      "Step 680, Loss 7.974793434143066\n",
      "Starting epoch 2/5, LR = [1.0000000000000012e-22]\n",
      "Step 690, Loss 7.997164726257324\n",
      "Step 700, Loss 7.929029941558838\n",
      "Starting epoch 3/5, LR = [1.0000000000000012e-21]\n",
      "Step 710, Loss 7.970700740814209\n",
      "Step 720, Loss 7.996031761169434\n",
      "Starting epoch 4/5, LR = [1.0000000000000013e-23]\n",
      "Step 730, Loss 7.95380163192749\n",
      "Step 740, Loss 7.999292373657227\n",
      "Starting epoch 5/5, LR = [1.0000000000000012e-22]\n",
      "Step 750, Loss 7.988996505737305\n",
      "Test Accuracy: 0.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1/5, LR = [1.0000000000000014e-24]\n",
      "Step 760, Loss 7.961159706115723\n",
      "Step 770, Loss 8.002476692199707\n",
      "Starting epoch 2/5, LR = [1.0000000000000013e-23]\n",
      "Step 780, Loss 8.017789840698242\n",
      "Step 790, Loss 7.972634315490723\n",
      "Starting epoch 3/5, LR = [1.0000000000000014e-25]\n",
      "Step 800, Loss 7.967706680297852\n",
      "Step 810, Loss 7.999509334564209\n",
      "Starting epoch 4/5, LR = [1.0000000000000014e-24]\n",
      "Step 820, Loss 7.9352827072143555\n",
      "Step 830, Loss 7.986834526062012\n",
      "Starting epoch 5/5, LR = [1.0000000000000015e-26]\n",
      "Step 840, Loss 7.948765754699707\n",
      "Step 850, Loss 7.968689918518066\n",
      "Test Accuracy: 0.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1/5, LR = [1.0000000000000014e-25]\n",
      "Step 860, Loss 8.117330551147461\n",
      "Step 870, Loss 8.116178512573242\n",
      "Starting epoch 2/5, LR = [1.0000000000000015e-27]\n",
      "Step 880, Loss 8.118268013000488\n",
      "Step 890, Loss 8.035907745361328\n",
      "Starting epoch 3/5, LR = [1.0000000000000015e-26]\n",
      "Step 900, Loss 8.051309585571289\n",
      "Step 910, Loss 8.123324394226074\n",
      "Starting epoch 4/5, LR = [1.0000000000000015e-28]\n",
      "Step 920, Loss 8.06251049041748\n",
      "Step 930, Loss 8.1046724319458\n",
      "Starting epoch 5/5, LR = [1.0000000000000015e-27]\n",
      "Step 940, Loss 8.103540420532227\n",
      "Test Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PiC\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "100%|██████████| 4/4 [00:10<00:00,  2.52s/it]\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.42s/it]\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.35s/it]\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.32s/it]\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.36s/it]\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.36s/it]\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.36s/it]\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.33s/it]\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.38s/it]\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.36s/it]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Plot**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3MIXOOuEThEL",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "outputId": "faea17be-fd93-4f7e-e23d-c6e614084a66"
   },
   "source": [
    "cifar100.plot(accuracy_train, accuracy_test, loss_train, loss_test)\n",
    "print('Best accuracy', best_accuracy)\n",
    "\n"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (5,) and (50,)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-19-c6a1389cc391>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mcifar100\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maccuracy_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccuracy_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Best accuracy'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbest_accuracy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\MLProject-Incremental.Learning\\Cifar100\\Cifar100.py\u001B[0m in \u001B[0;36mplot\u001B[1;34m(self, acc_train, acc_test, loss_train, loss_test)\u001B[0m\n\u001B[0;32m    101\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinspace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNUM_EPOCHS\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNUM_EPOCHS\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 103\u001B[1;33m         \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'mediumseagreen'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    104\u001B[0m         \u001B[1;31m# plt.plot(x, loss_test, color='lightseagreen')\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    105\u001B[0m         \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001B[0m in \u001B[0;36mplot\u001B[1;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2794\u001B[0m     return gca().plot(\n\u001B[0;32m   2795\u001B[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001B[1;32m-> 2796\u001B[1;33m         is not None else {}), **kwargs)\n\u001B[0m\u001B[0;32m   2797\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2798\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001B[0m in \u001B[0;36mplot\u001B[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1663\u001B[0m         \"\"\"\n\u001B[0;32m   1664\u001B[0m         \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcbook\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize_kwargs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmlines\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLine2D\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_alias_map\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1665\u001B[1;33m         \u001B[0mlines\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_lines\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1666\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mline\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mlines\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1667\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_line\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    223\u001B[0m                 \u001B[0mthis\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    224\u001B[0m                 \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 225\u001B[1;33m             \u001B[1;32myield\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_plot_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    226\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    227\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_next_color\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001B[0m in \u001B[0;36m_plot_args\u001B[1;34m(self, tup, kwargs)\u001B[0m\n\u001B[0;32m    389\u001B[0m             \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindex_of\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtup\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    390\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 391\u001B[1;33m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_xy_from_xy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    392\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    393\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcommand\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'plot'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001B[0m in \u001B[0;36m_xy_from_xy\u001B[1;34m(self, x, y)\u001B[0m\n\u001B[0;32m    268\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    269\u001B[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001B[1;32m--> 270\u001B[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001B[0m\u001B[0;32m    271\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m2\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    272\u001B[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001B[1;31mValueError\u001B[0m: x and y must have same first dimension, but have shapes (5,) and (50,)"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  }
 ]
}