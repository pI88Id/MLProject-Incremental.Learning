{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FineTuning\n",
    "from ...Cifar100.utils import plot\n",
    "\n",
    "####Hyper-parameters####\n",
    "DEVICE = 'cuda'\n",
    "NUM_CLASSES = 100\n",
    "BATCH_SIZE = 128\n",
    "CLASSES_BATCH =10\n",
    "STEPDOWN_EPOCHS = [49, 63]\n",
    "STEPDOWN_FACTOR = 5\n",
    "LR = 2\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.00001\n",
    "NUM_EPOCHS = 70\n",
    "########################\n",
    "\n",
    "parameters = {\n",
    "    'name': 'Finetuning'\n",
    "    'NUM_CLASSES': 100\n",
    "    'BATCH_SIZE' = 128\n",
    "    'CLASSES_BATCH' = 10\n",
    "    'STEPDOWN_EPOCHS' = [49, 63]\n",
    "    'STEPDOWN_FACTOR' = 5\n",
    "    'LR' = 2\n",
    "    'MOMENTUM' = 0.9\n",
    "    'WEIGHT_DECAY' = 0.00001\n",
    "    'NUM_EPOCHS' = 70\n",
    "}\n",
    "\n",
    "new_acc_train_list, new_loss_train_list, new_acc_test_list, new_loss_test_list, all_acc_list = incremental_learning()\n",
    "\n",
    "plot(new_acc_train_list, new_acc_test_list, new_loss_train_list, new_loss_test_list, all_acc_list, parameters)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}